{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### кратко\n",
    "Первоначально в соревновании стояла задача сегментации, для улучшения модели было решено обучить классификатор, который отсекал бы те снимки, на которых нет объектов искомых классов. Для этого из датасета получались макси, после чего сводились к метке 1 или 0 в зависимости от того, есть ли пиксели со значением 1 в масках. \n",
    "\n",
    "Были испробованы различные архитектуры: ResNet18, ResNet34, ResNet50, ResNext50, EfficientNet-b0, EfficientNet-b2. Так как маски выглядели просто как пятна, оказалось, что лучше всего работали не очень глубокие архитектуры.\n",
    "\n",
    "В качестве лоссов тестились BCE,BCE-Dice, Focal-Dice, лучше всего показал себя BCE.\n",
    "Был выбран ResNet34, предобученный на Imagenet, lr = 5e-3, scheduler = reduceOnPlateau.\n",
    "Лучший результат выбирался по validation accuracy за эпоху."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import cv2\n",
    "import pdb\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip, VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise, RandomBrightness, RandomContrast)\n",
    "from albumentations.pytorch import ToTensor\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RLE-Mask utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (1400, 2100, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((1400, 2100, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(1400 * 2100, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(1400, 2100, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         print(idx)\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = cv2.imread(image_path)\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == \"train\":\n",
    "        list_transforms.extend(\n",
    "            [   \n",
    "                \n",
    "                HorizontalFlip(p=0.5),\n",
    "                VerticalFlip(p=0.5),\n",
    "                RandomBrightness(),\n",
    "                RandomContrast(),\n",
    "                GaussNoise()\n",
    "            ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            Resize(512,768),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=4,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    df = pd.read_csv(df_path)\n",
    "    # https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "    df['Image'], df['Label'] = df['Image_Label'].str.split('_').str\n",
    "    df = df.pivot(index='Image',columns='Label',values='EncodedPixels')\n",
    "    df['defects'] = df.count(axis=1)\n",
    "    \n",
    "    train_df, val_df = train_test_split(df, test_size=0.1, stratify=df[\"defects\"], random_state=69)#\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = CloudDataset(df, data_folder, mean, std, phase)\n",
    "    dataloader = DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.resnet34( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/var/home/a.kulikov/clouds/model/resnet34-333f7ec4.pth'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_feats = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(in_features=in_feats,out_features=4,bias = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.layer1.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.layer2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # a *deeper* look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(input,target,threshold):\n",
    "    input = torch.sigmoid(input)\n",
    "    correct_preds_count = int(((input>threshold).reshape(-1).long()==target.reshape(-1).long()).sum())\n",
    "    return correct_preds_count/(target.shape[0]*target.shape[1]), correct_preds_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model):\n",
    "        self.num_workers = 6\n",
    "        self.batch_size = {\"train\": 8, \"val\": 8}\n",
    "        self.accumulation_steps = 32 // self.batch_size['train']\n",
    "        self.lr = 5e-3\n",
    "        self.num_epochs = 30\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.best_accuracy = float(0)\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                data_folder=data_folder,\n",
    "                df_path=train_df_path,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.iou_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        \n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        targets = targets.to(self.device)\n",
    "        outputs = self.net(images).float()\n",
    "        loss = self.criterion(outputs, targets)\n",
    "        \n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        meter = Meter(phase, epoch)\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "#         tk0 = tqdm(dataloader, total=total_batches)\n",
    "        self.optimizer.zero_grad()\n",
    "        accuracy_accum = 0\n",
    "        correct_answ_accum = 0\n",
    "        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n",
    "            images, targets = batch\n",
    "            #made classification targets from masks\n",
    "            targets = (targets.sum(dim=[2,3])>0).float()\n",
    "            loss, outputs = self.forward(images, targets)\n",
    "            loss = loss / self.accumulation_steps\n",
    "            batch_accuracy, correct_answ = calc_accuracy(outputs,targets.to(self.device).long(),0.5)\n",
    "            accuracy_accum += batch_accuracy\n",
    "            correct_answ_accum += correct_answ\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "#             tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        epoch_accuracy = correct_answ_accum/(total_batches*self.batch_size[phase]*4)\n",
    "        print(\"epoch_loss: \",epoch_loss,', mean batch accuracy: ', accuracy_accum / total_batches, ' epoch accuracy: ',epoch_accuracy)\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss, epoch_accuracy\n",
    "\n",
    "    def start(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "                'best_accuracy' : self.best_accuracy\n",
    "            }\n",
    "            with torch.no_grad():\n",
    "                val_loss, epoch_accuracy = self.iterate(epoch, \"val\")\n",
    "                self.scheduler.step(val_loss)\n",
    "            if epoch_accuracy > self.best_accuracy:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_accuracy\"] = self.best_accuracy = epoch_accuracy\n",
    "                torch.save(state, \"./model/classification_model_resnet34_all_data.pth\")\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = '/var/home/a.kulikov/clouds/data/sample_submission.csv'\n",
    "train_df_path = '/var/home/a.kulikov/clouds/data/train.csv'\n",
    "data_folder = \"/var/home/a.kulikov/clouds/data/\"\n",
    "test_data_folder = \"/var/home/a.kulikov/clouds/data/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0 | phase: train | ⏰: 22:15:09\n",
      "epoch_loss:  0.6254506495178622 , mean batch accuracy:  0.6455078125  epoch accuracy:  0.6449908088235294\n",
      "Starting epoch: 0 | phase: val | ⏰: 22:20:29\n",
      "epoch_loss:  0.6213184991741881 , mean batch accuracy:  0.6861213235294118  epoch accuracy:  0.6861213235294118\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 1 | phase: train | ⏰: 22:20:57\n",
      "epoch_loss:  0.5953654337345677 , mean batch accuracy:  0.6792279411764706  epoch accuracy:  0.6786534926470589\n",
      "Starting epoch: 1 | phase: val | ⏰: 22:26:12\n",
      "epoch_loss:  0.5972999549087357 , mean batch accuracy:  0.7136948529411765  epoch accuracy:  0.7136948529411765\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 2 | phase: train | ⏰: 22:26:39\n",
      "epoch_loss:  0.5763110792921746 , mean batch accuracy:  0.6948529411764706  epoch accuracy:  0.6942210477941176\n",
      "Starting epoch: 2 | phase: val | ⏰: 22:32:02\n",
      "epoch_loss:  0.5448783530908472 , mean batch accuracy:  0.7380514705882353  epoch accuracy:  0.7380514705882353\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 3 | phase: train | ⏰: 22:32:29\n",
      "epoch_loss:  0.5606292823110434 , mean batch accuracy:  0.7085822610294118  epoch accuracy:  0.7078354779411765\n",
      "Starting epoch: 3 | phase: val | ⏰: 22:37:47\n",
      "epoch_loss:  0.5877077106167289 , mean batch accuracy:  0.7127757352941176  epoch accuracy:  0.7127757352941176\n",
      "\n",
      "Starting epoch: 4 | phase: train | ⏰: 22:38:13\n",
      "epoch_loss:  0.5485582047635141 , mean batch accuracy:  0.7189797794117647  epoch accuracy:  0.7182329963235294\n",
      "Starting epoch: 4 | phase: val | ⏰: 22:43:43\n",
      "epoch_loss:  0.5244593968724504 , mean batch accuracy:  0.7355238970588235  epoch accuracy:  0.7355238970588235\n",
      "\n",
      "Starting epoch: 5 | phase: train | ⏰: 22:44:09\n",
      "epoch_loss:  0.5430119214031626 , mean batch accuracy:  0.7253561580882353  epoch accuracy:  0.7246668198529411\n",
      "Starting epoch: 5 | phase: val | ⏰: 22:49:31\n",
      "epoch_loss:  0.5320068203351077 , mean batch accuracy:  0.7431066176470589  epoch accuracy:  0.7431066176470589\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 6 | phase: train | ⏰: 22:49:59\n",
      "epoch_loss:  0.5386028433328166 , mean batch accuracy:  0.7235179227941176  epoch accuracy:  0.7227711397058824\n",
      "Starting epoch: 6 | phase: val | ⏰: 22:55:29\n",
      "epoch_loss:  0.4974040947854519 , mean batch accuracy:  0.7568933823529411  epoch accuracy:  0.7568933823529411\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 7 | phase: train | ⏰: 22:55:55\n",
      "epoch_loss:  0.5365361645269919 , mean batch accuracy:  0.7267922794117647  epoch accuracy:  0.7260454963235294\n",
      "Starting epoch: 7 | phase: val | ⏰: 23:01:13\n",
      "epoch_loss:  0.5083512573996011 , mean batch accuracy:  0.7490808823529411  epoch accuracy:  0.7490808823529411\n",
      "\n",
      "Starting epoch: 8 | phase: train | ⏰: 23:01:40\n",
      "epoch_loss:  0.5348087011233849 , mean batch accuracy:  0.7327665441176471  epoch accuracy:  0.7321346507352942\n",
      "Starting epoch: 8 | phase: val | ⏰: 23:07:04\n",
      "epoch_loss:  0.5117071661002496 , mean batch accuracy:  0.74609375  epoch accuracy:  0.74609375\n",
      "\n",
      "Starting epoch: 9 | phase: train | ⏰: 23:07:31\n",
      "epoch_loss:  0.528644639889107 , mean batch accuracy:  0.7352366727941176  epoch accuracy:  0.7344898897058824\n",
      "Starting epoch: 9 | phase: val | ⏰: 23:12:56\n",
      "epoch_loss:  0.5077901938382317 , mean batch accuracy:  0.7525275735294118  epoch accuracy:  0.7525275735294118\n",
      "\n",
      "Starting epoch: 10 | phase: train | ⏰: 23:13:22\n",
      "epoch_loss:  0.5254781247828814 , mean batch accuracy:  0.7312155330882353  epoch accuracy:  0.7305261948529411\n",
      "Starting epoch: 10 | phase: val | ⏰: 23:19:13\n",
      "epoch_loss:  0.6561048659769928 , mean batch accuracy:  0.6994485294117647  epoch accuracy:  0.6994485294117647\n",
      "Epoch    10: reducing learning rate of group 0 to 5.0000e-04.\n",
      "\n",
      "Starting epoch: 11 | phase: train | ⏰: 23:19:47\n",
      "epoch_loss:  0.5140249104074696 , mean batch accuracy:  0.7475298713235294  epoch accuracy:  0.7467256433823529\n",
      "Starting epoch: 11 | phase: val | ⏰: 23:25:10\n",
      "epoch_loss:  0.48499003490980935 , mean batch accuracy:  0.7693014705882353  epoch accuracy:  0.7693014705882353\n",
      "******** New optimal found, saving state ********\n",
      "\n",
      "Starting epoch: 12 | phase: train | ⏰: 23:25:36\n",
      "epoch_loss:  0.5119140365654055 , mean batch accuracy:  0.7440831801470589  epoch accuracy:  0.7433938419117647\n",
      "Starting epoch: 12 | phase: val | ⏰: 23:30:54\n",
      "epoch_loss:  0.5034656754749662 , mean batch accuracy:  0.7649356617647058  epoch accuracy:  0.7649356617647058\n",
      "\n",
      "Starting epoch: 13 | phase: train | ⏰: 23:31:20\n",
      "epoch_loss:  0.5084805129753316 , mean batch accuracy:  0.7524126838235294  epoch accuracy:  0.7516084558823529\n",
      "Starting epoch: 13 | phase: val | ⏰: 23:36:40\n",
      "epoch_loss:  0.5066807153908646 , mean batch accuracy:  0.7582720588235294  epoch accuracy:  0.7582720588235294\n",
      "\n",
      "Starting epoch: 14 | phase: train | ⏰: 23:37:07\n",
      "epoch_loss:  0.5059639107545509 , mean batch accuracy:  0.7487936580882353  epoch accuracy:  0.748046875\n",
      "Starting epoch: 14 | phase: val | ⏰: 23:42:32\n",
      "epoch_loss:  0.4853635274750345 , mean batch accuracy:  0.765625  epoch accuracy:  0.765625\n",
      "\n",
      "Starting epoch: 15 | phase: train | ⏰: 23:42:58\n",
      "epoch_loss:  0.5014171543914605 , mean batch accuracy:  0.7514935661764706  epoch accuracy:  0.7508042279411765\n",
      "Starting epoch: 15 | phase: val | ⏰: 23:48:16\n",
      "epoch_loss:  0.49373504672856894 , mean batch accuracy:  0.76171875  epoch accuracy:  0.76171875\n",
      "Epoch    15: reducing learning rate of group 0 to 5.0000e-05.\n",
      "\n",
      "Starting epoch: 16 | phase: train | ⏰: 23:48:43\n",
      "epoch_loss:  0.5012643411207724 , mean batch accuracy:  0.7542509191176471  epoch accuracy:  0.7535615808823529\n",
      "Starting epoch: 16 | phase: val | ⏰: 23:54:06\n",
      "epoch_loss:  0.4897320851245347 , mean batch accuracy:  0.7621783088235294  epoch accuracy:  0.7621783088235294\n",
      "\n",
      "Starting epoch: 17 | phase: train | ⏰: 23:54:33\n",
      "epoch_loss:  0.49903950840234756 , mean batch accuracy:  0.7555147058823529  epoch accuracy:  0.7548828125\n",
      "Starting epoch: 17 | phase: val | ⏰: 00:00:49\n",
      "epoch_loss:  0.48649901326964884 , mean batch accuracy:  0.7635569852941176  epoch accuracy:  0.7635569852941176\n",
      "\n",
      "Starting epoch: 18 | phase: train | ⏰: 00:01:32\n",
      "epoch_loss:  0.5004194332286716 , mean batch accuracy:  0.7563189338235294  epoch accuracy:  0.7558019301470589\n",
      "Starting epoch: 18 | phase: val | ⏰: 00:10:04\n",
      "epoch_loss:  0.48813079231802153 , mean batch accuracy:  0.7603400735294118  epoch accuracy:  0.7603400735294118\n",
      "\n",
      "Starting epoch: 19 | phase: train | ⏰: 00:10:44\n",
      "epoch_loss:  0.5010618795366848 , mean batch accuracy:  0.7551125919117647  epoch accuracy:  0.7543083639705882\n",
      "Starting epoch: 19 | phase: val | ⏰: 00:19:43\n",
      "epoch_loss:  0.4839735248071306 , mean batch accuracy:  0.7624080882352942  epoch accuracy:  0.7624080882352942\n",
      "\n",
      "Starting epoch: 20 | phase: train | ⏰: 00:20:49\n",
      "epoch_loss:  0.5028663644128862 , mean batch accuracy:  0.7514935661764706  epoch accuracy:  0.7506893382352942\n",
      "Starting epoch: 20 | phase: val | ⏰: 00:35:12\n",
      "epoch_loss:  0.4865426933940719 , mean batch accuracy:  0.7633272058823529  epoch accuracy:  0.7633272058823529\n",
      "\n",
      "Starting epoch: 21 | phase: train | ⏰: 00:36:09\n",
      "epoch_loss:  0.4977552241043133 , mean batch accuracy:  0.7567210477941176  epoch accuracy:  0.7560317095588235\n",
      "Starting epoch: 21 | phase: val | ⏰: 00:51:06\n",
      "epoch_loss:  0.4957584973205538 , mean batch accuracy:  0.7647058823529411  epoch accuracy:  0.7647058823529411\n",
      "\n",
      "Starting epoch: 22 | phase: train | ⏰: 00:52:09\n",
      "epoch_loss:  0.49716733741190505 , mean batch accuracy:  0.7553423713235294  epoch accuracy:  0.7545955882352942\n",
      "Starting epoch: 22 | phase: val | ⏰: 01:06:49\n",
      "epoch_loss:  0.4958642250036492 , mean batch accuracy:  0.7603400735294118  epoch accuracy:  0.7603400735294118\n",
      "\n",
      "Starting epoch: 23 | phase: train | ⏰: 01:07:59\n",
      "epoch_loss:  0.4979356133433826 , mean batch accuracy:  0.7531594669117647  epoch accuracy:  0.7526999080882353\n",
      "Starting epoch: 23 | phase: val | ⏰: 01:22:13\n",
      "epoch_loss:  0.48421991287785415 , mean batch accuracy:  0.7640165441176471  epoch accuracy:  0.7640165441176471\n",
      "Epoch    23: reducing learning rate of group 0 to 5.0000e-06.\n",
      "\n",
      "Starting epoch: 24 | phase: train | ⏰: 01:23:20\n",
      "epoch_loss:  0.4974777797675308 , mean batch accuracy:  0.7522403492647058  epoch accuracy:  0.7516084558823529\n",
      "Starting epoch: 24 | phase: val | ⏰: 01:38:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_loss:  0.49286108946099 , mean batch accuracy:  0.7635569852941176  epoch accuracy:  0.7635569852941176\n",
      "\n",
      "Starting epoch: 25 | phase: train | ⏰: 01:39:15\n",
      "epoch_loss:  0.4970493678770521 , mean batch accuracy:  0.7575252757352942  epoch accuracy:  0.7568933823529411\n",
      "Starting epoch: 25 | phase: val | ⏰: 01:53:21\n",
      "epoch_loss:  0.4856630815740894 , mean batch accuracy:  0.7637867647058824  epoch accuracy:  0.7637867647058824\n",
      "\n",
      "Starting epoch: 26 | phase: train | ⏰: 01:54:29\n",
      "epoch_loss:  0.49876191532787156 , mean batch accuracy:  0.7553423713235294  epoch accuracy:  0.7547679227941176\n",
      "Starting epoch: 26 | phase: val | ⏰: 02:09:07\n",
      "epoch_loss:  0.48654372486121517 , mean batch accuracy:  0.7642463235294118  epoch accuracy:  0.7642463235294118\n",
      "\n",
      "Starting epoch: 27 | phase: train | ⏰: 02:10:16\n",
      "epoch_loss:  0.4988954532343675 , mean batch accuracy:  0.7549402573529411  epoch accuracy:  0.7541360294117647\n",
      "Starting epoch: 27 | phase: val | ⏰: 02:24:05\n",
      "epoch_loss:  0.483316822525333 , mean batch accuracy:  0.7628676470588235  epoch accuracy:  0.7628676470588235\n",
      "\n",
      "Starting epoch: 28 | phase: train | ⏰: 02:25:12\n",
      "epoch_loss:  0.49753364076947465 , mean batch accuracy:  0.7542509191176471  epoch accuracy:  0.7536190257352942\n",
      "Starting epoch: 28 | phase: val | ⏰: 02:39:41\n",
      "epoch_loss:  0.4846109000637251 , mean batch accuracy:  0.7642463235294118  epoch accuracy:  0.7642463235294118\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#resnet_18_aug_40epochs+focal_loss+from_scratch\n",
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 anaconda(A.Kulikov)",
   "language": "python",
   "name": "python3_akulikov"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
