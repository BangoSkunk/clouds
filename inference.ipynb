{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  кратко\n",
    "Предикты получал произведением выхода классификатора и сегментатора( так получался наибольший скор), для постобработки использовал общедоступные функции удаления небольших областей + convex hull для большего охвата масок. Почему-то блендинг у меня не зашел, а про TTA я вспомнил за несколько часов до конца соревнования и не успел его нормально написать. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet Inference kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "import pdb\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from albumentations import (Normalize, Compose, Resize)\n",
    "from albumentations.pytorch import ToTensor\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "# from model import Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    '''Dataset for test prediction'''\n",
    "    def __init__(self, root, df, mean, std):\n",
    "        self.root = root\n",
    "        df['Image'] = df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
    "        self.fnames = df['Image'].unique().tolist()\n",
    "        self.num_samples = len(self.fnames)\n",
    "        self.transform = Compose(\n",
    "            [\n",
    "                Resize(512,768),\n",
    "                Normalize(mean=mean, std=std, p=1),\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname)\n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image=image)[\"image\"]\n",
    "        return fname, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting small masks\n",
    "def post_process(probability, threshold, min_size):\n",
    "    \"\"\"\n",
    "    Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored\n",
    "    \"\"\"\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    mask = cv2.resize(mask, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((350, 525), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying masks for bigger square via convex hull\n",
    "def draw_convex_hull(mask, mode='convex'):\n",
    "    mask = np.array(mask, dtype = np.uint8)\n",
    "    img = np.zeros(mask.shape)\n",
    "    contours, hier = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for c in contours:\n",
    "        if mode=='rect': # simple rectangle\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), -1)\n",
    "        elif mode=='convex': # minimum convex hull\n",
    "            hull = cv2.convexHull(c)\n",
    "            cv2.drawContours(img, [hull], 0, (255, 255, 255),-1)\n",
    "        elif mode=='approx':\n",
    "            epsilon = 0.02*cv2.arcLength(c,True)\n",
    "            approx = cv2.approxPolyDP(c,epsilon,True)\n",
    "            cv2.drawContours(img, [approx], 0, (255, 255, 255),-1)\n",
    "        else: # minimum area rectangle\n",
    "            rect = cv2.minAreaRect(c)\n",
    "            box = cv2.boxPoints(rect)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(img, [box], 0, (255, 255, 255),-1)\n",
    "    return img/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission_path = './data/sample_submission.csv'\n",
    "test_data_folder = \"./data/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold [0.3, 0.3, 0.3, 0.3]\n"
     ]
    }
   ],
   "source": [
    "# initialize test dataloader\n",
    "best_threshold = [0.3,0.4,0.3,0.3]#resnet\n",
    "num_workers = 2\n",
    "batch_size = 4\n",
    "print('best_threshold', best_threshold)\n",
    "min_size = 11000\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "df = pd.read_csv(sample_submission_path)\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, mean, std),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path2 = \"./model/Unet34_bcedice_enc_dec_all_pic.pth\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = Unet(\"resnet34\", encoder_weights=None, classes=4,activation=None,attention_type='scse',center=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "state = torch.load(ckpt_path2, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ckpt_path = \"./model/classification_model_resnet34_all_data.pth\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "cl_model = resnet34()\n",
    "in_feats = cl_model.fc.in_features\n",
    "cl_model.fc = torch.nn.Linear(in_features=in_feats,out_features=4,bias = True)\n",
    "cl_model.to(device)\n",
    "cl_model.eval()\n",
    "cl_state = torch.load(class_ckpt_path) \n",
    "cl_model.load_state_dict(cl_state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [03:03<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# start prediction\n",
    "predictions = []\n",
    "mapping = {0:'Fish',1:'Flower',2:'Gravel',3:'Sugar'}\n",
    "for i, batch in enumerate(tqdm(testset)):\n",
    "    fnames, images = batch\n",
    "    cl_preds = torch.sigmoid(cl_model(images.to(device)))\n",
    "    batch_preds = torch.sigmoid(model(images.to(device)))\n",
    "    batch_preds = cl_preds[:,:,None,None]*batch_preds\n",
    "    batch_preds = batch_preds.detach().cpu().numpy()\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            pred, num = post_process(pred, best_threshold[cls], min_size)\n",
    "            pred = draw_convex_hull(pred)\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{mapping[cls]}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "# save predictions to submission.csv\n",
    "df = pd.DataFrame(predictions, columns=['Image_Label', 'EncodedPixels'])\n",
    "df.to_csv(\"./submissions/Unet34_bce_dice_submission_11k_connected_resnet_class.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 anaconda(A.Kulikov)",
   "language": "python",
   "name": "python3_akulikov"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
